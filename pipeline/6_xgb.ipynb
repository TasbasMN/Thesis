{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/run/media/nazif/2F946E411BA61D49/thesis\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.plotting import plot_importance\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_columns(df, cols):\n",
    "\n",
    "    # Create a scaler object\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Scale the specified columns in the dataframe\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[cols] = scaler.fit_transform(df[cols])\n",
    "\n",
    "    return df_scaled\n",
    "\n",
    "\n",
    "def report_performance(model, X, y):\n",
    "    # Make predictions on the input data\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    roc_auc = roc_auc_score(y, y_pred)\n",
    "\n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC AUC': roc_auc,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_feature_importances(model):\n",
    "    \"\"\"\n",
    "    Get feature importances of every column from a model.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the feature importances for each column, with column names as keys.\n",
    "    \"\"\"\n",
    "    feature_importances = {}\n",
    "\n",
    "    # Check if the model has the attribute \"feature_importances_\"\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        # Get the feature importances\n",
    "        importances = model.feature_importances_\n",
    "\n",
    "        # Get the column names\n",
    "        if hasattr(model, \"get_booster\"):\n",
    "            column_names = model.get_booster().feature_names\n",
    "        elif hasattr(model, \"named_steps\"):\n",
    "            column_names = model.named_steps[\"preprocessor\"].get_feature_names_out(\n",
    "            )\n",
    "        else:\n",
    "            column_names = []\n",
    "\n",
    "        # Store the feature importances with their respective column names\n",
    "        for feature_name, importance in zip(column_names, importances):\n",
    "            feature_importances[feature_name] = importance\n",
    "\n",
    "        # Sort the feature importances in descending order\n",
    "        feature_importances = dict(\n",
    "            sorted(feature_importances.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    return feature_importances\n",
    "\n",
    "\n",
    "def compare_importances(model1_importances, model2_importances):\n",
    "    # Convert dictionaries to DataFrames\n",
    "    df1 = pd.DataFrame(model1_importances.items(),\n",
    "                       columns=['Feature', 'Model 1'])\n",
    "    df2 = pd.DataFrame(model2_importances.items(),\n",
    "                       columns=['Feature', 'Model 2'])\n",
    "\n",
    "    # Merge the DataFrames on the 'Feature' column\n",
    "    merged_df = pd.merge(df1, df2, on='Feature', how='outer')\n",
    "\n",
    "    # Calculate change and add indicators\n",
    "    merged_df['Change'] = merged_df.apply(\n",
    "        lambda row: '+' if row['Model 2'] > row['Model 1'] else ('-' if row['Model 2'] < row['Model 1'] else ''), axis=1)\n",
    "    merged_df['Importance Change'] = merged_df['Model 2'] - \\\n",
    "        merged_df['Model 1']\n",
    "\n",
    "    # Sort by Importance Change descending\n",
    "    merged_df = merged_df.sort_values(by='Importance Change', ascending=False)\n",
    "\n",
    "    return merged_df.style.apply(\n",
    "        lambda row: [\n",
    "            'color:black; background-color: #98ff98'\n",
    "            if val == '+'\n",
    "            else (\n",
    "                'color:black; background-color: #8B0000' if val == '-' else ''\n",
    "            )\n",
    "            for val in row\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "\n",
    "def compare_metrics(model1_metrics, model2_metrics):\n",
    "    # Convert dictionaries to DataFrames\n",
    "    df1 = pd.DataFrame(model1_metrics.items(), columns=['Metric', 'Model 1'])\n",
    "    df2 = pd.DataFrame(model2_metrics.items(), columns=['Metric', 'Model 2'])\n",
    "\n",
    "    # Merge the DataFrames on the 'Metric' column\n",
    "    merged_df = pd.merge(df1, df2, on='Metric', how='outer')\n",
    "\n",
    "    # Calculate change and add indicators\n",
    "    merged_df['Change'] = merged_df.apply(\n",
    "        lambda row: '+' if row['Model 2'] > row['Model 1'] else ('-' if row['Model 2'] < row['Model 1'] else ''), axis=1)\n",
    "    merged_df['Change In Value'] = merged_df['Model 2'] - merged_df['Model 1']\n",
    "\n",
    "    return merged_df.style.apply(\n",
    "        lambda row: [\n",
    "            'color:black; background-color: #98ff98'\n",
    "            if val == '+'\n",
    "            else (\n",
    "                'color:black; background-color: #8B0000' if val == '-' else ''\n",
    "            )\n",
    "            for val in row\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "\n",
    "def drop_column_and_score(X, y):\n",
    "    # List of metrics to calculate\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score,\n",
    "        'Precision': precision_score,\n",
    "        'Recall': recall_score,\n",
    "        'F1 Score': f1_score\n",
    "    }\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Train an initial XGBoost model\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    initial_scores = calculate_metrics(metrics, y_test, model.predict(X_test))\n",
    "    scores = {'Initial Model': initial_scores}\n",
    "    # Drop each column one by one and train a new model\n",
    "    for column in X.columns:\n",
    "        # Create a new X without the current column\n",
    "        X_dropped = X.drop(column, axis=1)\n",
    "\n",
    "        # Split the modified data into train and test sets\n",
    "        X_train_dropped, X_test_dropped, y_train, y_test = train_test_split(\n",
    "            X_dropped, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "        # Train a new XGBoost model without the current column\n",
    "        model_dropped = XGBClassifier()\n",
    "        model_dropped.fit(X_train_dropped, y_train)\n",
    "\n",
    "        # Calculate the scores of the new model\n",
    "        column_scores = calculate_metrics(\n",
    "            metrics, y_test, model_dropped.predict(X_test_dropped))\n",
    "        scores[f'Dropped {column}'] = column_scores\n",
    "\n",
    "    return pd.DataFrame(scores).T\n",
    "\n",
    "\n",
    "def calculate_metrics(metrics, y_true, y_pred):\n",
    "    scores = {}\n",
    "    for metric_name, metric_func in metrics.items():\n",
    "        score = metric_func(y_true, y_pred)\n",
    "        scores[metric_name] = score\n",
    "    return scores\n",
    "\n",
    "\n",
    "def stylizer(df):\n",
    "    # Define a function to apply color based on cell values\n",
    "    def apply_color(row):\n",
    "        color = []  # List to store color values for each cell in the row\n",
    "        for i, cell in enumerate(row):\n",
    "            # Check if the cell value is equal to the first cell value in the DataFrame\n",
    "            if cell == df.iloc[0, i]:\n",
    "                color.append('background-color: black')  # If equal, set background color to black\n",
    "            else:\n",
    "                # Calculate the difference between the cell value and the first cell value\n",
    "                diff = cell - df.iloc[0, i]\n",
    "                # Calculate the maximum difference in the DataFrame\n",
    "                max_diff = df.values.max() - df.values.min()\n",
    "                if diff > 0:\n",
    "                    # If the difference is positive, calculate the intensity of green color based on the difference\n",
    "                    intensity = min(1.0, 0.2 + 0.8 * (diff / max_diff))\n",
    "                    color.append(f'background-color: rgba(0, 255, 0, {intensity:.2f})')  # Green with intensity\n",
    "                else:\n",
    "                    # If the difference is negative, calculate the intensity of red color based on the difference\n",
    "                    intensity = min(1.0, 0.2 - 0.8 * (diff / max_diff))\n",
    "                    color.append(f'background-color: rgba(255, 0, 0, {intensity:.2f})')  # Red with intensity\n",
    "        return color\n",
    "\n",
    "    # Apply the color function to each row of the DataFrame using the `.style.apply()` method\n",
    "    return df.style.apply(apply_color, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_most_correlated_features(data, threshold=0.7):\n",
    "    # Compute the correlation matrix\n",
    "    correlation_matrix = data.corr().abs()\n",
    "\n",
    "    # Extract the upper triangle of the correlation matrix\n",
    "    upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    # Find feature pairs with correlation above the threshold\n",
    "    correlated_pairs = upper_triangle.unstack().sort_values(ascending=False)\n",
    "    correlated_pairs = correlated_pairs[correlated_pairs > threshold]\n",
    "\n",
    "    return correlated_pairs\n",
    "\n",
    "\n",
    "def get_average_correlations(df: pd.DataFrame) -> pd.Series:\n",
    "    return df.corr().abs().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results/5_features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\n",
    "    \"pred_energy\",\n",
    "    \"pred_num_basepairs\",\n",
    "    \"pred_seed_basepairs\",\n",
    "    \"ta_log10\",\n",
    "    \"sps_mean\",\n",
    "    \"anchor_a\",\n",
    "    \"6mer_seed\",\n",
    "    \"match_8\",\n",
    "    \"6mer_seed_1_mismatch\",\n",
    "    \"compensatory_site\",\n",
    "    \"supplementary_site\",\n",
    "    \"supplementary_site_2\",\n",
    "    \"empty_seed\",\n",
    "    \"9_consecutive_match_anywhere\",\n",
    "    \"mirna_conservation\",\n",
    "\n",
    "\n",
    "    \"seed_8mer\",\n",
    "    \"seed_7mer_a1\",\n",
    "    \"seed_7mer_m8\",\n",
    "    \"seed_compensatory\",\n",
    "    \"seed_clash_2\",\n",
    "    \"seed_clash_3\",\n",
    "    \"seed_clash_4\",\n",
    "    \"seed_clash_5\",\n",
    "    \"mre_au_content\",\n",
    "    \"au_content\",\n",
    "    \"label\"\n",
    "]\n",
    "\n",
    "df = df[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_energy</th>\n",
       "      <th>pred_num_basepairs</th>\n",
       "      <th>pred_seed_basepairs</th>\n",
       "      <th>ta_log10</th>\n",
       "      <th>sps_mean</th>\n",
       "      <th>anchor_a</th>\n",
       "      <th>6mer_seed</th>\n",
       "      <th>match_8</th>\n",
       "      <th>6mer_seed_1_mismatch</th>\n",
       "      <th>compensatory_site</th>\n",
       "      <th>supplementary_site</th>\n",
       "      <th>supplementary_site_2</th>\n",
       "      <th>empty_seed</th>\n",
       "      <th>9_consecutive_match_anywhere</th>\n",
       "      <th>mirna_conservation</th>\n",
       "      <th>seed_8mer</th>\n",
       "      <th>seed_7mer_a1</th>\n",
       "      <th>seed_7mer_m8</th>\n",
       "      <th>seed_compensatory</th>\n",
       "      <th>seed_clash_2</th>\n",
       "      <th>seed_clash_3</th>\n",
       "      <th>seed_clash_4</th>\n",
       "      <th>seed_clash_5</th>\n",
       "      <th>mre_au_content</th>\n",
       "      <th>au_content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-27.7</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>3.393</td>\n",
       "      <td>-8.18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.670732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26.2</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>3.393</td>\n",
       "      <td>-8.18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-23.6</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>3.393</td>\n",
       "      <td>-8.18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-23.8</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>3.393</td>\n",
       "      <td>-8.18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-24.0</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>3.393</td>\n",
       "      <td>-8.18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_energy  pred_num_basepairs  pred_seed_basepairs  ta_log10  sps_mean  \\\n",
       "0        -27.7                  20                    6     3.393     -8.18   \n",
       "1        -26.2                  17                    6     3.393     -8.18   \n",
       "2        -23.6                  19                    6     3.393     -8.18   \n",
       "3        -23.8                  19                    6     3.393     -8.18   \n",
       "4        -24.0                  18                    6     3.393     -8.18   \n",
       "\n",
       "   anchor_a  6mer_seed  match_8  6mer_seed_1_mismatch  compensatory_site  \\\n",
       "0         1          1        1                     0                  1   \n",
       "1         1          1        1                     0                  1   \n",
       "2         0          1        0                     0                  1   \n",
       "3         1          1        0                     0                  1   \n",
       "4         0          1        1                     0                  0   \n",
       "\n",
       "   supplementary_site  supplementary_site_2  empty_seed  \\\n",
       "0                   1                     0           0   \n",
       "1                   1                     0           0   \n",
       "2                   1                     1           0   \n",
       "3                   1                     1           0   \n",
       "4                   0                     0           0   \n",
       "\n",
       "   9_consecutive_match_anywhere  mirna_conservation  seed_8mer  seed_7mer_a1  \\\n",
       "0                             1                 2.0          1             0   \n",
       "1                             1                 2.0          1             0   \n",
       "2                             1                 2.0          0             0   \n",
       "3                             1                 2.0          0             1   \n",
       "4                             1                 2.0          0             0   \n",
       "\n",
       "   seed_7mer_m8  seed_compensatory  seed_clash_2  seed_clash_3  seed_clash_4  \\\n",
       "0             0                  0             1             0             0   \n",
       "1             0                  0             1             0             0   \n",
       "2             0                  0             0             0             0   \n",
       "3             0                  0             0             0             0   \n",
       "4             1                  0             0             0             0   \n",
       "\n",
       "   seed_clash_5  mre_au_content  au_content  label  \n",
       "0             0        0.590909    0.670732      1  \n",
       "1             0        0.454545    0.634146      1  \n",
       "2             0        0.500000    0.585366      1  \n",
       "3             0        0.636364    0.621951      1  \n",
       "4             0        0.500000    0.585366      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scaling columns (disabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scaling columns\n",
    "# cols_to_scale = [\"pred_energy\", \"ta_log10\", \"sps_mean\"]\n",
    "# df = scale_columns(df, cols_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scale midpoint using minmax\n",
    "# minmax = MinMaxScaler(feature_range=(0, 1))\n",
    "# df[\"midpoint\"] = minmax.fit_transform(df[\"midpoint\"].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(objective=\"binary:logistic\")\n",
    "model.fit(X_train, y_train)\n",
    "report = report_performance(model, X_test, y_test)\n",
    "importances = get_feature_importances(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5925099 , 0.02779814, 0.01254048, 0.04486499, 0.03184418,\n",
       "       0.00669375, 0.        , 0.00801963, 0.00535922, 0.00789661,\n",
       "       0.00517622, 0.00598456, 0.03774297, 0.00715259, 0.13452187,\n",
       "       0.01029878, 0.00493244, 0.0097351 , 0.00119641, 0.0011681 ,\n",
       "       0.00289158, 0.00177233, 0.00510955, 0.02800726, 0.00678322],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m col_drop_results \u001b[39m=\u001b[39m drop_column_and_score(X, y)\n",
      "Cell \u001b[0;32mIn[3], line 157\u001b[0m, in \u001b[0;36mdrop_column_and_score\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m# Train a new XGBoost model without the current column\u001b[39;00m\n\u001b[1;32m    156\u001b[0m model_dropped \u001b[39m=\u001b[39m XGBClassifier()\n\u001b[0;32m--> 157\u001b[0m model_dropped\u001b[39m.\u001b[39;49mfit(X_train_dropped, y_train)\n\u001b[1;32m    159\u001b[0m \u001b[39m# Calculate the scores of the new model\u001b[39;00m\n\u001b[1;32m    160\u001b[0m column_scores \u001b[39m=\u001b[39m calculate_metrics(\n\u001b[1;32m    161\u001b[0m     metrics, y_test, model_dropped\u001b[39m.\u001b[39mpredict(X_test_dropped))\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/thesis-4DYweHFz-py3.11/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/thesis-4DYweHFz-py3.11/lib/python3.11/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1491\u001b[0m     params,\n\u001b[1;32m   1492\u001b[0m     train_dmatrix,\n\u001b[1;32m   1493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1502\u001b[0m )\n\u001b[1;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/thesis-4DYweHFz-py3.11/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/thesis-4DYweHFz-py3.11/lib/python3.11/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/thesis-4DYweHFz-py3.11/lib/python3.11/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "col_drop_results = drop_column_and_score(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stylized_df = stylizer(col_drop_results)\n",
    "stylized_df.set_caption(\"Model\")\n",
    "stylized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = X.corr()\n",
    "\n",
    "plt.figure(figsize=(20, 18))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_most_correlated_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(list(importances.keys()), list(importances.values()))\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avgcorr = get_average_correlations(X)\n",
    "\n",
    "avgcorr = avgcorr.sort_values(ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(avgcorr.index, avgcorr.values)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Average Correlation')\n",
    "plt.title('Average Correlations of Features (Descending Order)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define the hyperparameter grid for grid search\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.1, 0.01, 0.001],                # Default: 0.3\n",
    "#     'n_estimators': [100, 300, 500],                    # Default: 100\n",
    "#     'max_depth': [3, 6, 9],                            # Default: 6\n",
    "#     'min_child_weight': [1, 3, 5],                     # Default: 1\n",
    "#     'subsample': [0.8, 0.9, 1.0],                     # Default: 1.0\n",
    "#     'colsample_bytree': [0.8, 0.9, 1.0],              # Default: 1.0\n",
    "#     'reg_lambda': [1.0, 2.0, 3.0],                    # Default: 1.0\n",
    "#     'reg_alpha': [0.0, 0.1, 0.5],                     # Default: 0.0\n",
    "#     'gamma': [0, 0.1, 0.2],                           # Default: 0\n",
    "# }\n",
    "\n",
    "# # Perform grid search with cross-validation\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best hyperparameters and model\n",
    "# best_params = grid_search.best_params_\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Model:\", best_model)\n",
    "\n",
    "# # Evaluate the best model on the testing set\n",
    "# accuracy = best_model.score(X_test, y_test)  # Replace X_test and y_test with your testing data\n",
    "# print(\"Accuracy on Testing Set:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_after_cv = xgb.XGBClassifier(**grid_search.best_params_)\n",
    "\n",
    "# model_after_cv.fit(X_train, y_train)\n",
    "# score_after_cv = model_after_cv.score(X_test, y_test)\n",
    "# print(f\"accuracy after cv: {score_after_cv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage_increase = (model_after_cv.score(X_test, y_test) - model.score(X_test, y_test)) / model.score(X_test, y_test) * 100\n",
    "\n",
    "# print(f\"The accuracy increased by {percentage_increase:.2f}% after CV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the trained model\n",
    "model.save_model('results/model.xgb')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-4DYweHFz-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
